---
title: "Theoretical and Empirical Advances in Forest Pruning"
collection: 'publications'
permalink: /publications/2025-03-06-ForestPruning
excerpt: 
date: 2025-03-06
venue:
paperurl:
preprinturl: https://arxiv.org/abs/2401.05535
citation: 'Dorador, A. (2025). &quot;Theoretical and Empirical Advances in Forest Pruning.&quot;'
note: 'preprint'
---

<b> Abstract </b> : 
Regression forests have long delivered state-of-the-art accuracy, often outperforming regression trees and even neural networks, but they suffer from limited interpretability as ensemble methods.
In this work, we revisit forest pruning, an approach that aims to have the best of both worlds: the accuracy of regression forests and the interpretability of regression trees.
This pursuit, whose foundation lies at the core of random forest theory, has seen vast success in empirical studies.
In this paper, we contribute theoretical results that support and qualify those empirical findings; namely, we prove the asymptotic advantage of a Lasso-pruned forest over its unpruned counterpart under weak assumptions, as well as high-probability finite-sample generalization bounds for regression forests pruned according to the main methods, which we then validate by way of simulation.
Then, we test the accuracy of pruned regression forests against their unpruned counterparts on 19 different datasets (16 synthetic, 3 real). We find that in the vast majority of scenarios tested, there is at least one forest-pruning method that yields equal or better accuracy than the original full forest (in expectation), while just using a small fraction of the trees.
We show that, in some cases, the reduction in the size of the forest is so dramatic that the resulting sub-forest can be meaningfully merged into a single tree, obtaining a level of interpretability that is qualitatively superior to that of the original regression forest, which remains a black box.

---
